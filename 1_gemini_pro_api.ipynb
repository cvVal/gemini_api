{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e78c394-7f24-4401-a0d0-ed7fe2948bd7",
   "metadata": {},
   "source": [
    "# Gemini Pro API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7c6a76",
   "metadata": {},
   "source": [
    "### Install the necessary libraries using pip, Python's package installer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ed51a-d472-4120-a893-1cecfc95df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5506d-066e-41ac-a348-2903a3cf31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cf401-a072-4718-a254-b24f56c293d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89ef7ca",
   "metadata": {},
   "source": [
    "Import the necessary modules and functions from these libraries.\n",
    "Also import the `os` module, which provides a way of using operating system dependent functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb086fa-fe64-40de-baa3-a2b1eaf474de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9279703",
   "metadata": {},
   "source": [
    "Get a API key from https://ai.google.dev/. \n",
    "Locally in the same directory, create a .env file with the GOOGLE_API_KEY placeholder and its secret value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce08d73-e26a-4ec9-8f1b-78b0f0806560",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c838195-7060-454c-9dd1-219b29bd3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ.get('GOOGLE_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f00f38a-33d2-4e19-80f6-0177f9c0c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the Google API key to configure the `genai` module.\n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))\n",
    "\n",
    "# listing available models\n",
    "for m in genai.list_models():\n",
    "    if 'generateContent' in m.supported_generation_methods:\n",
    "        print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db1a77e-2b80-4cfd-8bbd-30785d18cae5",
   "metadata": {},
   "source": [
    "## Generating Text From Text Inputs: Gemini PRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae3185-cfdc-45e9-8b98-bc591a0dccf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the `GenerativeModel` class, passing in the name of the model to use ('gemini-pro').\n",
    "# Use this model to generate content based on various prompts.\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "response = model.generate_content('Translate quantum mechanics concepts into a story for teenagers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b837a65-ceb7-477a-8596-1c39ec52745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c90ec56-f9eb-4a8d-be26-8782e2257150",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3940228d-1d6e-4d77-a8aa-3626812a7e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content('Tell me a joke.')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3192d8a6-8de4-4367-8453-1dea79173ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.prompt_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9642339-3e29-4f57-b70a-364c0a9f529c",
   "metadata": {},
   "source": [
    "## Streaming\n",
    "\n",
    "Streaming refers to the process of sending the generated response to the user piece-by-piece as the model  progressively  computes it. This is different from the traditional approach where the model generates the entire response at once before sending it to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1747dbb-7461-4485-836f-d81d7bc3ab94",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Write an imaginary scientific paper that proposes a new theory of quantum gravity.'\n",
    "\n",
    "#Without streaming the response\n",
    "#response = model.generate_content(prompt)\n",
    "#print(response.text)\n",
    "\n",
    "#Streaming the response\n",
    "response = model.generate_content(prompt, stream=True)\n",
    "for chunk in response:\n",
    "    print(chunk.text, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c103f",
   "metadata": {},
   "source": [
    "# Generating Text From Image and Text Inputs: Gemini Pro Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc81dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20270ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3251a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Locally in the same directory, add an image.\n",
    "from PIL import Image\n",
    "img = Image.open('image_fsh.jpeg')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "#Loading the API key and authenticating to Gemini\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# Configuring the API key\n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the Gemini PRO vision model\n",
    "model = genai.GenerativeModel('gemini-pro-vision')\n",
    "\n",
    "# response = model.generate_content(img)\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ba5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating content for a prompt\n",
    "prompt = 'Describe this image for me, please.'\n",
    "\n",
    "response = model.generate_content([prompt, img])\n",
    "\n",
    "# Displaying the response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9dd28e",
   "metadata": {},
   "source": [
    "# Gemini API Generation Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c476556e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa79d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "# Loading the API key and authenticating to Gemini\n",
    "# Get a API key from https://ai.google.dev/\n",
    "# Locally in the same directory, create a .env file with the GOOGLE_API_KEY placeholder and its secret value\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "os.environ.get('GOOGLE_API_KEY')\n",
    "\n",
    "# Configuring the API key\n",
    "genai.configure(api_key=os.environ.get('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325e4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the Gemini PRO model\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Generating content for a prompt\n",
    "prompt = 'Rewrite \"The Raven\" by Edgar Allan Poe in the style of a modern rock song.'\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Displaying the response\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to see the default values\n",
    "genai.get_model('models/gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af90018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation Config with default attribute values\n",
    "# This Generation Config object will be passed as an argument to genai.generativeModel to modify the \n",
    "# generation parameters\n",
    "my_generation_config = genai.types.GenerationConfig()\n",
    "\n",
    "# Generation Config with specific values\n",
    "# my_generation_config = genai.types.GenerationConfig(\n",
    "#     candidate_count=1,\n",
    "#     stop_sequence=[','],\n",
    "#     max_output_tokens=32000,\n",
    "#     temperature=0.4,\n",
    "#     top_p=1,\n",
    "#     top_k=1\n",
    "# )\n",
    "\n",
    "# 1st Option. Will change the generation paramateres for all the queries\n",
    "model = genai.GenerativeModel('gemini-pro', generation_config=my_generation_config)\n",
    "\n",
    "# 2nd Option. Will change the generation paramateres only for one query.\n",
    "response = model.generate_content(prompt, generation_config=my_generation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50483ae8",
   "metadata": {},
   "source": [
    "# Gemini API Generation Parameters Explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807e0a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(genai.types.GenerationConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a40595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config_temp_0 = genai.types.GenerationConfig(\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "generation_config_temp_1 = genai.types.GenerationConfig(\n",
    "    temperature=1.0\n",
    ")\n",
    "\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "prompt = 'What is the meaning of life?'\n",
    "\n",
    "response_temp_0 = model.generate_content(prompt, stream=True, generation_config=generation_config_temp_0)\n",
    "response_temp_1 = model.generate_content(prompt, stream=True, generation_config=generation_config_temp_1)\n",
    "\n",
    "print(\"Response with Temperature 0:\")\n",
    "for response in model.generate_content(prompt, stream=True, generation_config=generation_config_temp_0):\n",
    "  print(response.text)\n",
    "\n",
    "print(\"*\" * 100)\n",
    "\n",
    "print(\"Response with Temperature 1:\")\n",
    "for response in model.generate_content(prompt, stream=True, generation_config=generation_config_temp_1):\n",
    "  print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a97e67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
